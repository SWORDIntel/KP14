#!/usr/bin/env python3
"""
Malware Code Extractor
----------------------
This tool attempts to extract code-like structures from binary files,
recovering potential source code from the decrypted malware samples.
It uses a combination of disassembly, pattern recognition, and
heuristic-based analysis to identify and reconstruct code elements.
"""

import os
import sys
import argparse
import binascii
import struct
import re
import json
from collections import defaultdict

try:
    import capstone
    HAS_CAPSTONE = True
except ImportError:
    HAS_CAPSTONE = False
    print("[!] Capstone not available, advanced disassembly will be limited")

try:
    import r2pipe
    HAS_R2 = True
except ImportError:
    HAS_R2 = False
    print("[!] r2pipe not available, function analysis will be limited")

# Configuration
DEFAULT_OUTPUT_DIR = "extracted_code"
ARCH_PATTERNS = {
    'x86': [
        rb'\x55\x8b\xec',                # push ebp; mov ebp, esp
        rb'\x55\x89\xe5',                # push ebp; mov ebp, esp
        rb'\x53\x56\x57',                # push ebx; push esi; push edi
        rb'\x83\xec[\x00-\xff]',         # sub esp, X
        rb'\x8b[\x44\x45\x54\x55][\x00-\xff]',  # mov eax/ebx/edx/esp, [ebp+X]
    ],
    'x64': [
        rb'\x48\x89\x5c\x24',           # mov [rsp+X], rbx
        rb'\x48\x83\xec',               # sub rsp, X
        rb'\x48[\x8b\x89\x8d][\xc0-\xff]', # mov r64, r/m64
    ],
    'arm': [
        rb'[\x00-\xff]{2}\x2d\xe9',     # push {XX}
        rb'[\x00-\xff]{2}\xd0\xe5',     # ldr XX, [XX]
        rb'\x0d\xc0\xa0\xe1',           # mov ip, sp
    ]
}

STRING_PATTERNS = [
    rb'[\x20-\x7E]{6,}',                # ASCII strings (at least 6 chars)
    rb'(?:[\x20-\x7E]\x00){4,}',        # Unicode strings (at least 4 chars)
]

API_INDICATORS = [
    'Create', 'Open', 'Close', 'Read', 'Write', 'Get', 'Set', 'Query',
    'Alloc', 'Free', 'Lock', 'Unlock', 'Init', 'Connect', 'Send', 'Recv',
    'Load', 'Reg', 'Crypt', 'File', 'Mem', 'Thread', 'Process', 'Module',
    'Http', 'Socket', 'Winsock', 'Crypt', 'Encrypt', 'Decrypt'
]

def detect_architecture(data):
    """Detect the likely architecture of the binary data."""
    scores = {arch: 0 for arch in ARCH_PATTERNS}
    
    for arch, patterns in ARCH_PATTERNS.items():
        for pattern in patterns:
            matches = re.findall(pattern, data)
            scores[arch] += len(matches)
    
    # Normalize scores
    total = sum(scores.values()) or 1
    for arch in scores:
        scores[arch] = scores[arch] / total
    
    return scores

def extract_strings(data):
    """Extract ASCII and Unicode strings from binary data."""
    strings = []
    
    for pattern in STRING_PATTERNS:
        for match in re.finditer(pattern, data):
            string_data = match.group(0)
            if b'\x00' in string_data:  # Unicode
                try:
                    decoded = string_data.decode('utf-16-le').strip()
                    if decoded and len(decoded) >= 4:
                        strings.append({
                            'offset': match.start(),
                            'string': decoded,
                            'type': 'unicode',
                            'context': binascii.hexlify(data[max(0, match.start()-8):match.start()+len(string_data)+8]).decode()
                        })
                except Exception: # Changed bare except
                    pass
            else:  # ASCII
                try:
                    decoded = string_data.decode('ascii').strip()
                    if decoded and len(decoded) >= 6:
                        strings.append({
                            'offset': match.start(),
                            'string': decoded,
                            'type': 'ascii',
                            'context': binascii.hexlify(data[max(0, match.start()-8):match.start()+len(string_data)+8]).decode()
                        })
                except Exception: # Changed bare except
                    pass
    
    return strings

def identify_potential_apis(strings):
    """Identify strings that might be API calls based on common patterns."""
    apis = []
    
    for string in strings:
        s = string['string']
        for indicator in API_INDICATORS:
            if indicator in s:
                apis.append({
                    'offset': string['offset'],
                    'api': s,
                    'indicator': indicator,
                    'context': string['context']
                })
                break
    
    return apis

def find_function_boundaries(data):
    """Identify potential function boundaries in the binary."""
    boundaries = []
    
    prologue_patterns = [
        rb'\x55\x8b\xec',              # push ebp; mov ebp, esp (x86)
        rb'\x55\x89\xe5',              # push ebp; mov ebp, esp (gcc style)
        rb'\x40\x53',                  # push rbx (x64)
        rb'\x48\x83\xec',              # sub rsp, X (x64)
        rb'\x48\x89\x5c\x24'           # mov [rsp+X], rbx (x64)
    ]
    
    epilogue_patterns = [
        rb'\x5d\xc3',                  # pop ebp; ret (x86)
        rb'\xc9\xc3',                  # leave; ret (x86)
        rb'\x5b\xc3',                  # pop ebx; ret
        rb'\x48\x83\xc4[\x00-\xff]\xc3',  # add rsp, X; ret (x64)
        rb'\xc3'                       # ret
    ]
    
    # Find function starts (prologues)
    for pattern in prologue_patterns:
        for match in re.finditer(pattern, data):
            boundaries.append({
                'offset': match.start(),
                'type': 'prologue',
                'pattern': binascii.hexlify(pattern).decode()
            })
    
    # Find function ends (epilogues)
    for pattern in epilogue_patterns:
        for match in re.finditer(pattern, data):
            boundaries.append({
                'offset': match.start(),
                'type': 'epilogue',
                'pattern': binascii.hexlify(pattern).decode()
            })
    
    return sorted(boundaries, key=lambda x: x['offset'])

def analyze_with_r2(file_path, output_dir):
    """Perform deeper analysis using radare2 if available."""
    if not HAS_R2:
        return None
    
    print(f"[+] Analyzing {file_path} with radare2...")
    r2 = r2pipe.open(file_path)
    r2.cmd("aaa")  # Auto-analyze
    
    functions = r2.cmdj("aflj")  # Get function list as JSON
    if not functions:
        functions = []
    
    function_details = []
    for func in functions:
        # Get function disassembly
        disasm = r2.cmd(f"pdf @ {func['name']}")
        
        # Get function variables
        vars_info = r2.cmdj(f"afvj @ {func['name']}")
        
        function_details.append({
            'name': func['name'],
            'offset': func['offset'],
            'size': func['size'],
            'disassembly': disasm,
            'variables': vars_info
        })
    
    # Save the analysis results
    with open(os.path.join(output_dir, "r2_analysis.json"), 'w') as f:
        json.dump({
            'file': file_path,
            'functions': function_details
        }, f, indent=2)
    
    # Generate pseudo-C code where possible
    for func in functions:
        pseudo_c = r2.cmd(f"pdc @ {func['name']}")
        if pseudo_c and len(pseudo_c) > 10:  # Only if we got meaningful output
            with open(os.path.join(output_dir, f"{func['name']}.c"), 'w') as f:
                f.write(f"// Auto-generated pseudo-C for {func['name']} at 0x{func['offset']:x}\n")
                f.write(pseudo_c)
    
    r2.quit()
    return function_details

def disassemble_with_capstone(data, arch_info):
    """Disassemble binary using Capstone if available."""
    if not HAS_CAPSTONE:
        return None
    
    # Determine mode based on arch detection
    if arch_info['x64'] > 0.5:
        md = capstone.Cs(capstone.CS_ARCH_X86, capstone.CS_MODE_64)
    elif arch_info['x86'] > 0.5:
        md = capstone.Cs(capstone.CS_ARCH_X86, capstone.CS_MODE_32)
    elif arch_info['arm'] > 0.5:
        md = capstone.Cs(capstone.CS_ARCH_ARM, capstone.CS_MODE_ARM)
    else:
        # Default to x86
        md = capstone.Cs(capstone.CS_ARCH_X86, capstone.CS_MODE_32)
    
    md.detail = True
    disassembly = []
    
    # Disassemble in chunks to handle potential errors
    chunk_size = 4096
    for i in range(0, len(data), chunk_size):
        chunk = data[i:i+chunk_size]
        try:
            for insn in md.disasm(chunk, i):
                disassembly.append({
                    'address': insn.address,
                    'mnemonic': insn.mnemonic,
                    'op_str': insn.op_str,
                    'bytes': binascii.hexlify(insn.bytes).decode()
                })
        except Exception: # Changed bare except
            # Skip problematic chunks
            continue
    
    return disassembly

def reconstruct_pseudo_code(disassembly, strings, apis, boundaries):
    """Attempt to reconstruct pseudo-code from disassembly and analysis data."""
    if not disassembly:
        return []
    
    # Group instructions into potential functions
    functions = []
    current_function = None
    
    # Convert boundaries to a map for quick lookup
    boundary_map = {}
    for b in boundaries:
        boundary_map[b['offset']] = b['type']
    
    # Convert strings to a map for quick lookup
    string_map = {}
    for s in strings:
        string_map[s['offset']] = s['string']
    
    # Convert APIs to a map for quick lookup
    api_map = {}
    for a in apis:
        api_map[a['offset']] = a['api']
    
    # Process instructions to identify functions
    for insn in disassembly:
        addr = insn['address']
        
        # Check if this is a function boundary
        if addr in boundary_map:
            if boundary_map[addr] == 'prologue':
                if current_function:
                    functions.append(current_function)
                current_function = {
                    'start': addr,
                    'end': None,
                    'instructions': [],
                    'calls': [],
                    'strings_used': []
                }
            elif boundary_map[addr] == 'epilogue' and current_function:
                current_function['end'] = addr
                functions.append(current_function)
                current_function = None
        
        # Add instruction to current function if we're in one
        if current_function:
            current_function['instructions'].append(insn)
            
            # Track function calls
            if insn['mnemonic'] == 'call':
                target = insn['op_str']
                current_function['calls'].append({
                    'address': addr,
                    'target': target
                })
            
            # Check for string references
            # This is simplified and would need more accurate memory reference tracking
            for offset, string_val in string_map.items(): # Renamed string to string_val
                if hex(offset)[2:] in insn['op_str']:
                    current_function['strings_used'].append({
                        'address': addr,
                        'string': string_val # Use renamed variable
                    })
    
    # If we ended with an open function, close it
    if current_function:
        functions.append(current_function)
    
    # Generate pseudo-code for each identified function
    pseudo_code = []
    
    for i, func in enumerate(functions):
        # Skip very small functions (likely false positives)
        if len(func['instructions']) < 3:
            continue
        
        func_name = f"function_{i:04d}"
        code = [f"// {func_name} at address 0x{func['start']:x}"]
        code.append(f"void {func_name}() {{")
        
        # Add string references as comments
        if func['strings_used']:
            code.append("    // String references:")
            for s in func['strings_used']:
                code.append(f"    // - \"{s['string']}\"")
            code.append("")
        
        # Add function calls
        if func['calls']:
            code.append("    // Function calls:")
            for call in func['calls']:
                code.append(f"    // - {call['target']}")
            code.append("")
        
        # Add basic instruction flow
        code.append("    /* Assembly:")
        for insn in func['instructions'][:20]:  # Limit to first 20 instructions
            code.append(f"     * 0x{insn['address']:x}: {insn['mnemonic']} {insn['op_str']}")
        if len(func['instructions']) > 20:
            code.append(f"     * ... ({len(func['instructions']) - 20} more instructions)")
        code.append("     */")
        
        code.append("}")
        pseudo_code.append("\n".join(code))
    
    return pseudo_code

def process_file(file_path, output_dir):
    """Process a single file and extract code-like structures."""
    print(f"[+] Processing {file_path}")
    
    # Create output directory
    file_output_dir = os.path.join(output_dir, os.path.basename(file_path))
    os.makedirs(file_output_dir, exist_ok=True)
    
    # Read the file
    with open(file_path, 'rb') as f:
        data = f.read()
    
    print(f"[+] File size: {len(data)} bytes")
    
    # Detect architecture
    arch_info = detect_architecture(data)
    print(f"[+] Architecture detection: {', '.join([f'{k}: {v:.2f}' for k, v in arch_info.items()])}")
    
    # Extract strings
    strings = extract_strings(data)
    print(f"[+] Extracted {len(strings)} strings")
    
    # Save strings to file
    with open(os.path.join(file_output_dir, "strings.txt"), 'w') as f:
        for s in strings:
            f.write(f"[{s['offset']:08x}] ({s['type']}): {s['string']}\n")
    
    # Identify potential APIs
    apis = identify_potential_apis(strings)
    print(f"[+] Identified {len(apis)} potential API references")
    
    # Save APIs to file
    with open(os.path.join(file_output_dir, "apis.txt"), 'w') as f:
        for api in apis:
            f.write(f"[{api['offset']:08x}]: {api['api']} (matched: {api['indicator']})\n")
    
    # Find function boundaries
    boundaries = find_function_boundaries(data)
    print(f"[+] Found {len(boundaries)} potential function boundaries")
    
    # Save boundaries to file
    with open(os.path.join(file_output_dir, "functions.txt"), 'w') as f:
        for b in boundaries:
            f.write(f"[{b['offset']:08x}] {b['type']}: {b['pattern']}\n")
    
    # Deeper analysis with radare2 if available
    r2_analysis = analyze_with_r2(file_path, file_output_dir)
    if r2_analysis:
        print(f"[+] Radare2 analysis identified {len(r2_analysis)} functions")
    
    # Disassemble with Capstone if available
    disassembly = disassemble_with_capstone(data, arch_info)
    if disassembly:
        print(f"[+] Disassembled {len(disassembly)} instructions")
        
        # Save disassembly to file
        with open(os.path.join(file_output_dir, "disassembly.txt"), 'w') as f:
            for insn in disassembly:
                f.write(f"0x{insn['address']:08x}: {insn['mnemonic']} {insn['op_str']} ({insn['bytes']})\n")
    
    # Reconstruct pseudo-code
    if disassembly:
        pseudo_code = reconstruct_pseudo_code(disassembly, strings, apis, boundaries)
        print(f"[+] Generated {len(pseudo_code)} pseudo-code snippets")
        
        # Save pseudo-code to file
        for i, code in enumerate(pseudo_code):
            with open(os.path.join(file_output_dir, f"function_{i:04d}.c"), 'w') as f:
                f.write(code)
        
        # Create a combined file with all pseudo-code
        with open(os.path.join(file_output_dir, "all_functions.c"), 'w') as f:
            f.write("// Combined pseudo-code from binary analysis\n")
            f.write(f"// File: {file_path}\n")
            f.write(f"// Date: {os.path.getmtime(file_path)}\n\n") # Requires os import
            
            for code in pseudo_code:
                f.write(code)
                f.write("\n\n")
    
    print(f"[+] Analysis complete. Results saved to {file_output_dir}")

def main():
    parser = argparse.ArgumentParser(description="Extract code-like structures from binary files")
    parser.add_argument("input", help="Input file or directory to process")
    parser.add_argument("-o", "--output", default=DEFAULT_OUTPUT_DIR, help="Output directory")
    parser.add_argument("-r", "--recursive", action="store_true", help="Process directories recursively")
    args = parser.parse_args()
    
    # Create output directory
    os.makedirs(args.output, exist_ok=True)
    
    # Process input
    if os.path.isfile(args.input):
        process_file(args.input, args.output)
    elif os.path.isdir(args.input):
        print("[+] Processing directory: {}".format(args.input))
        
        for root, dirs, files in os.walk(args.input) if args.recursive else [(args.input, [], os.listdir(args.input))]:
            for file_item in files: # Renamed to avoid conflict with 'files' module
                file_path = os.path.join(root, file_item)
                if os.path.isfile(file_path):
                    process_file(file_path, args.output)
            
            if not args.recursive:
                break
    else:
        print("[!] Error: {} is not a valid file or directory".format(args.input))
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
