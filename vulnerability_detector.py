import logging
import re
import os
import pickle # For saving/loading vectorizer
import joblib # For saving/loading model
from typing import Dict, List, Optional, Any 
import traceback # For more detailed error logging
import subprocess # For (optional) MO execution
import shutil # For checking `mo` in PATH (though not strictly used for `mo` path finding here)


from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# Imports for ONNX conversion
from skl2onnx import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType
import numpy # Often needed for ONNX, and for TF-IDF output type

# Imports for OpenVINO Inference
from openvino.runtime import Core, Tensor


class VulnerabilityDetector:
    def __init__(self, 
                 logger: Optional[logging.Logger] = None, 
                 ml_model_path: Optional[str] = "trained_vuln_model.joblib", 
                 ml_vectorizer_path: Optional[str] = "vuln_vectorizer.pkl",
                 ir_model_xml_path: Optional[str] = None): # Added ir_model_xml_path
        self.logger = logger if logger else logging.getLogger(self.__class__.__name__)
        if not logger and not logging.getLogger().hasHandlers():
            logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        
        self.ml_model_path: Optional[str] = ml_model_path
        self.ml_vectorizer_path: Optional[str] = ml_vectorizer_path
        self.ml_model: Optional[LogisticRegression] = None
        self.ml_vectorizer: Optional[TfidfVectorizer] = None
        self.onnx_model_path: Optional[str] = None 
        
        self.ir_model_xml_path: Optional[str] = ir_model_xml_path # Store provided IR path
        self.ir_model_bin_path: Optional[str] = None 
        self.compiled_model_ir: Optional[Any] = None # For OpenVINO CompiledModel


        # Attempt to load scikit-learn model first if paths are provided
        if self.ml_model_path and self.ml_vectorizer_path:
            self.logger.info(f"Attempting to load scikit-learn components: model from '{self.ml_model_path}', vectorizer from '{self.ml_vectorizer_path}'.")
            if not self.load_trained_ml_components(self.ml_model_path, self.ml_vectorizer_path):
                self.logger.warning("Failed to load one or both scikit-learn components.")
        elif self.ml_model_path or self.ml_vectorizer_path:
            self.logger.warning("Both ml_model_path and ml_vectorizer_path must be provided to load scikit-learn components.")
        
        # Attempt to load OpenVINO IR model if path is provided
        if self.ir_model_xml_path: # Use the attribute that was set from constructor arg
            self.logger.info(f"Attempting to load OpenVINO IR model from '{self.ir_model_xml_path}'.")
            if not self.load_openvino_ir_model(self.ir_model_xml_path): # Pass the path to the method
                self.logger.warning(f"Failed to load OpenVINO IR model from {self.ir_model_xml_path}. OpenVINO inference will not be available.")
        
        if not self.ml_model and not self.compiled_model_ir:
             self.logger.info("No scikit-learn or OpenVINO model loaded during initialization. Train a model or load components manually.")
        elif self.compiled_model_ir:
             self.logger.info("OpenVINO IR model loaded. It will be preferred for ML-based vulnerability detection.")
        elif self.ml_model:
             self.logger.info("Scikit-learn model loaded. It will be used for ML-based vulnerability detection as OpenVINO IR model is not available.")


        self.vulnerable_patterns = {
            "strcpy": re.compile(r"\bstrcpy\s*\("),
            "strcat": re.compile(r"\bstrcat\s*\("),
            "sprintf_non_literal_format": re.compile(r"\bsprintf\s*\(\s*[a-zA-Z_][a-zA-Z0-9_]*\s*,\s*(?!\s*\"(?:\\\"|[^\"])*\")\s*[a-zA-Z_][a-zA-Z0-9_]*"),
            "sprintf": re.compile(r"\bsprintf\s*\("),
            "gets": re.compile(r"\bgets\s*\("),
            "scanf": re.compile(r"\bscanf\s*\("),
            "system": re.compile(r"\bsystem\s*\("),
            "memcpy": re.compile(r"\bmemcpy\s*\("),
            "strncpy": re.compile(r"\bstrncpy\s*\("),
            "strncat": re.compile(r"\bstrncat\s*\("),
            "vsprintf": re.compile(r"\bvsprintf\s*\("),
        }
        self.pattern_descriptions = {
            "strcpy": "Use of strcpy: potential buffer overflow if destination buffer is too small or input not null-terminated.",
            "strcat": "Use of strcat: potential buffer overflow if destination buffer is too small or inputs not null-terminated.",
            "sprintf_non_literal_format": "Use of sprintf with a non-literal format string: high risk of format string vulnerability.",
            "sprintf": "Use of sprintf: general use can lead to buffer overflows if output buffer is too small or format string issues.",
            "gets": "Use of gets: extremely dangerous, always leads to buffer overflow if input is uncontrolled. Should never be used.",
            "memcpy": "Use of memcpy: potential buffer overflow if 'count' argument is larger than destination buffer. Also, if src and dst overlap, behavior is undefined (use memmove).",
            "strncpy": "Use of strncpy: safer than strcpy, but does not guarantee null-termination if source is larger than n. Ensure manual null-termination.",
            "strncat": "Use of strncat: safer than strcat, but requires careful calculation of 'n' to prevent overflow and ensure null-termination.",
            "scanf": "Use of scanf family (scanf, fscanf, sscanf) without width specifiers in format strings (e.g., %s instead of %99s) can lead to buffer overflows.",
            "system": "Use of system(): potential command injection if the command string is derived from or contains unsanitized external input.",
            "vsprintf": "Use of vsprintf: similar dangers to sprintf (buffer overflows, format string vulnerabilities).",
        }
        for pattern in self.vulnerable_patterns:
            if pattern not in self.pattern_descriptions:
                self.pattern_descriptions[pattern] = "No specific description available for this pattern."

    def _c_code_tokenizer(self, code_snippet: str) -> List[str]:
        if not code_snippet:
            return []
        code = code_snippet.lower() 
        token_pattern = re.compile(
            r"[a-zA-Z_]\w*|[0-9]+|==|!=|<=|>=|&&|\|\||<<|>>|->|\+\+|--|[=;\-\+\*\/\%<>&\|\(\)\{\}\[\]!.,:?~^]"
        )
        tokens = token_pattern.findall(code)
        return tokens

    def scan_for_vulnerabilities(self, code_content: str, file_path: Optional[str] = None) -> Dict[str, Any]:
        self.logger.info(f"Scanning for vulnerabilities in {'file: ' + file_path if file_path else 'direct code content'}.")
        findings: List[Dict[str, Any]] = []
        
        lines = code_content.splitlines()
        pattern_scan_order = [
            "gets", "sprintf_non_literal_format", "strcpy", "strcat",
            "sprintf", "vsprintf", "scanf", "system", "memcpy",
            "strncpy", "strncat"
        ]
        active_patterns = {k: self.vulnerable_patterns[k] for k in pattern_scan_order if k in self.vulnerable_patterns}

        for pattern_name, compiled_regex in active_patterns.items():
            for i, line in enumerate(lines):
                if pattern_name == "sprintf" and any(f["line_number"] == i + 1 and f["pattern_name"] == "sprintf_non_literal_format" for f in findings):
                    continue
                for match in compiled_regex.finditer(line):
                    findings.append({
                        "pattern_name": pattern_name,
                        "line_number": i + 1,
                        "line_content": line.strip(),
                        "description": self.pattern_descriptions.get(pattern_name, "No description available."),
                        "match_start_column": match.start()
                    })
        
        file_scanned_name = os.path.basename(file_path) if file_path else "direct_content_scan"
        self.logger.info(f"Found {len(findings)} potential pattern-based vulnerabilities in {file_scanned_name}.")
        
        ml_results = self.predict_vulnerabilities_ml(code_content, file_path) # This now acts as unified interface
        
        return {
            "file_scanned": file_scanned_name,
            "pattern_vulnerabilities_found": findings,
            "ml_vulnerability_analysis": ml_results, 
            "status": "completed"
        }

    def perform_taint_analysis(self, code_content: str, file_path: Optional[str] = None, existing_findings: Optional[List[Dict[str, Any]]] = None) -> List[Dict[str, Any]]:
        target_name = os.path.basename(file_path) if file_path else "direct code content"
        self.logger.info(f"Placeholder: Taint analysis called for {target_name}.")
        if existing_findings is not None:
            self.logger.info(f"  Received {len(existing_findings)} existing findings. Taint analysis would augment or use these.")
            return existing_findings
        else:
            self.logger.info("  No existing findings provided to taint analysis.")
            return []

    def train_vulnerability_model(self, 
                                  training_corpus: List[str], 
                                  training_labels: List[str],
                                  max_features: int = 5000,
                                  test_size_split: float = 0.2,
                                  random_state_split: int = 42
                                 ) -> Dict[str, Any]:
        self.logger.info(f"Starting ML model training for vulnerability detection with {len(training_corpus)} samples.")

        if not training_corpus or not training_labels:
            self.logger.error("Training corpus or labels are empty. Training aborted.")
            return {"status": "error_no_data", "message": "Training corpus or labels cannot be empty."}
        if len(training_corpus) != len(training_labels):
            self.logger.error(f"Mismatch in length of training corpus ({len(training_corpus)}) and labels ({len(training_labels)}).")
            return {"status": "error_data_mismatch", "message": "Corpus and labels length mismatch."}

        self.logger.info(f"Initializing and fitting TF-IDF vectorizer (max_features={max_features})...")
        self.ml_vectorizer = TfidfVectorizer(
            tokenizer=self._c_code_tokenizer, 
            token_pattern=None, 
            max_features=max_features, 
            lowercase=True 
        )
        try:
            X_tfidf = self.ml_vectorizer.fit_transform(training_corpus)
            self.logger.info(f"TF-IDF Vectorizer fitted. Vocabulary size: {len(self.ml_vectorizer.vocabulary_)}, Features: {X_tfidf.shape[1]}")
            
            if not self.ml_vectorizer_path:
                self.ml_vectorizer_path = "vuln_vectorizer.pkl"
                self.logger.info(f"Vectorizer path not set, using default: {self.ml_vectorizer_path}")
            
            vectorizer_dir = os.path.dirname(self.ml_vectorizer_path)
            if vectorizer_dir and not os.path.exists(vectorizer_dir):
                 os.makedirs(vectorizer_dir, exist_ok=True)
            with open(self.ml_vectorizer_path, 'wb') as f_vec:
                pickle.dump(self.ml_vectorizer, f_vec)
            self.logger.info(f"Vectorizer saved to '{self.ml_vectorizer_path}'")
        except Exception as e:
            self.logger.error(f"Error fitting or saving TF-IDF vectorizer: {e}")
            self.ml_vectorizer = None
            return {"status": "error_vectorizer", "message": f"Vectorizer error: {e}"}

        self.logger.info("Training Logistic Regression model...")
        self.ml_model = LogisticRegression(random_state=random_state_split, max_iter=1000, solver='liblinear', class_weight='balanced')
        
        X_train, X_test, y_train, y_test = train_test_split(
            X_tfidf, training_labels, test_size=test_size_split, 
            random_state=random_state_split, stratify=training_labels if len(set(training_labels)) > 1 else None
        )
        self.logger.info(f"Data split: {X_train.shape[0]} train samples, {X_test.shape[0]} test samples.")

        try:
            self.ml_model.fit(X_train, y_train)
            self.logger.info("Logistic Regression model training completed.")

            if not self.ml_model_path:
                self.ml_model_path = "trained_vuln_model.joblib"
                self.logger.info(f"Model path not set, using default: {self.ml_model_path}")

            model_dir = os.path.dirname(self.ml_model_path)
            if model_dir and not os.path.exists(model_dir):
                 os.makedirs(model_dir, exist_ok=True)
            joblib.dump(self.ml_model, self.ml_model_path)
            self.logger.info(f"Model saved to '{self.ml_model_path}'")

            if self.export_model_to_onnx(): 
                 self.convert_onnx_to_openvino_ir() 

        except Exception as e:
            self.logger.error(f"Error training or saving/exporting models: {e}")
            self.ml_model = None
            return {"status": "error_model_processing", "message": f"Model training/saving/export error: {e}"}

        accuracy = None
        if X_test.shape[0] > 0:
            try:
                y_pred = self.ml_model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
                self.logger.info(f"Model accuracy on test set: {accuracy:.4f}")
            except Exception as e_acc:
                self.logger.warning(f"Could not calculate accuracy on test set: {e_acc}")
        
        return {
            "status": "training_complete",
            "message": "ML model training finished. Model, vectorizer, ONNX model saved. MO command generated.",
            "model_path": self.ml_model_path,
            "vectorizer_path": self.ml_vectorizer_path,
            "onnx_model_path": self.onnx_model_path,
            "ir_model_xml_path": self.ir_model_xml_path,
            "num_features": X_tfidf.shape[1],
            "accuracy_on_test_split": accuracy
        }

    def load_trained_ml_components(self, model_path: str, vectorizer_path: str) -> bool:
        model_loaded = False
        vectorizer_loaded = False

        if not os.path.exists(model_path):
            self.logger.warning(f"ML model file not found at {model_path}.")
        else:
            try:
                self.ml_model = joblib.load(model_path)
                self.ml_model_path = model_path
                self.logger.info(f"ML model loaded successfully from {model_path}.")
                model_loaded = True
            except Exception as e:
                self.logger.error(f"Error loading ML model from {model_path}: {e}")
                self.ml_model = None

        if not os.path.exists(vectorizer_path):
            self.logger.warning(f"ML vectorizer file not found at {vectorizer_path}.")
        else:
            try:
                with open(vectorizer_path, 'rb') as f_vec:
                   self.ml_vectorizer = pickle.load(f_vec)
                self.ml_vectorizer_path = vectorizer_path
                self.logger.info(f"ML vectorizer loaded successfully from {vectorizer_path}.")
                vectorizer_loaded = True
            except Exception as e:
                self.logger.error(f"Error loading ML vectorizer from {vectorizer_path}: {e}")
                self.ml_vectorizer = None
        
        if model_loaded and vectorizer_loaded:
            return True
        else: 
            if model_loaded: self.ml_model = None 
            if vectorizer_loaded: self.ml_vectorizer = None
            return False

    def predict_vulnerabilities_ml(self, code_content: str, file_path: Optional[str] = None) -> Dict[str, Any]:
        file_scanned_name = os.path.basename(file_path) if file_path else "direct_content_scan"
        self.logger.info(f"ML vulnerability prediction called for {file_scanned_name}.")

        # Prioritize OpenVINO IR model if available and loaded
        if self.compiled_model_ir and self.ml_vectorizer and self.ml_model: # self.ml_model needed for class labels
            self.logger.info("Attempting ML prediction using OpenVINO IR model.")
            return self.predict_vulnerabilities_openvino(code_content, file_path)
        
        # Fallback to scikit-learn model
        if not self.ml_model or not self.ml_vectorizer:
            self.logger.warning("Scikit-learn ML model or vectorizer not loaded. Cannot perform ML-based prediction.")
            return {
                "file_scanned": file_scanned_name, "ml_findings": [], "status": "no_ml_model_loaded",
                "engine_type": "sklearn_logistic_regression" if self.ml_model else "none",
                "model_path_used": self.ml_model_path, "vectorizer_path_used": self.ml_vectorizer_path
            }

        self.logger.info(f"Using scikit-learn ML model from: {self.ml_model_path}")
        self.logger.info(f"Using scikit-learn ML vectorizer from: {self.ml_vectorizer_path}")
        
        ml_findings = []
        try:
            transformed_data = self.ml_vectorizer.transform([code_content])
            self.logger.debug(f"  Code content transformed to TF-IDF shape: {transformed_data.shape}")
            
            prediction = self.ml_model.predict(transformed_data)
            probabilities = self.ml_model.predict_proba(transformed_data)
            
            vulnerable_class_label = "vulnerable" 
            vulnerable_class_idx = -1

            if hasattr(self.ml_model, 'classes_'):
                class_list = list(self.ml_model.classes_)
                if vulnerable_class_label in class_list:
                    vulnerable_class_idx = class_list.index(vulnerable_class_label)
                elif len(class_list) == 2 : 
                    positive_class_candidate = class_list[1] 
                    self.logger.warning(f"Label '{vulnerable_class_label}' not found in model classes ({class_list}). Assuming positive class is '{positive_class_candidate}' at index 1.")
                    vulnerable_class_label = positive_class_candidate
                    vulnerable_class_idx = 1

            predicted_label = prediction[0]
            confidence = 0.0

            if vulnerable_class_idx != -1 and len(probabilities[0]) > vulnerable_class_idx :
                confidence = probabilities[0][vulnerable_class_idx]
            
            self.logger.info(f"  ML prediction (scikit-learn): '{predicted_label}', Confidence (for '{vulnerable_class_label}' class): {confidence:.4f}")

            if predicted_label == vulnerable_class_label: 
                ml_findings.append({
                    "vulnerability_type": predicted_label, 
                    "confidence": confidence,
                    "details": "ML model (scikit-learn) predicted a potential vulnerability based on code patterns.",
                    "line_number_start": -1, 
                    "line_number_end": -1,
                    "snippet_if_applicable": code_content[:200] + "..." if len(code_content) > 200 else code_content
                })
        except Exception as e:
            self.logger.error(f"Error during scikit-learn ML prediction: {e}")
            return {
                "file_scanned": file_scanned_name, "ml_findings": [], "status": "error_ml_prediction",
                "engine_type": "sklearn_logistic_regression", "error_message": str(e),
                "model_path_used": self.ml_model_path, "vectorizer_path_used": self.ml_vectorizer_path
            }

        return {
            "file_scanned": file_scanned_name,
            "ml_findings": ml_findings,
            "status": "ml_prediction_complete",
            "engine_type": "sklearn_logistic_regression", 
            "model_path_used": self.ml_model_path,
            "vectorizer_path_used": self.ml_vectorizer_path
        }

    def export_model_to_onnx(self, onnx_model_path: Optional[str] = None) -> bool:
        if not self.ml_model:
            self.logger.error("Scikit-learn ML model (self.ml_model) is not available. Train or load a model first.")
            return False
        if not self.ml_vectorizer:
            self.logger.error("TF-IDF Vectorizer (self.ml_vectorizer) is not available. It's needed for input feature count.")
            return False

        if onnx_model_path:
            self.onnx_model_path = onnx_model_path
        elif self.ml_model_path:
            self.onnx_model_path = self.ml_model_path.replace(".joblib", ".onnx")
        else:
            self.onnx_model_path = "trained_vuln_model.onnx" 
        
        self.logger.info(f"Attempting to export ML model to ONNX at: {self.onnx_model_path}")

        try:
            num_features = len(self.ml_vectorizer.vocabulary_)
            if num_features == 0:
                dummy_transformed = self.ml_vectorizer.transform(["dummy test string"])
                num_features = dummy_transformed.shape[1]
            if num_features == 0:
                self.logger.error("Vectorizer reported 0 features. Cannot define ONNX input shape.")
                return False
                
            self.logger.info(f"Defining ONNX model input shape with {num_features} features.")
            initial_type = [('float_input', FloatTensorType([None, num_features]))]

            self.logger.info(f"Converting scikit-learn ML model to ONNX format (target_opset=12)...")
            onnx_model = convert_sklearn(self.ml_model, initial_types=initial_type, target_opset=12)

            onnx_dir = os.path.dirname(self.onnx_model_path)
            if onnx_dir and not os.path.exists(onnx_dir):
                os.makedirs(onnx_dir, exist_ok=True)
                self.logger.info(f"Created directory for ONNX model: {onnx_dir}")

            with open(self.onnx_model_path, "wb") as f:
                f.write(onnx_model.SerializeToString())
            
            self.logger.info(f"ML model exported successfully to ONNX format at {self.onnx_model_path}")
            return True
        except Exception as e:
            self.logger.error(f"Failed to export ML model to ONNX: {e}")
            self.logger.debug(traceback.format_exc())
            self.onnx_model_path = None 
            return False

    def convert_onnx_to_openvino_ir(self, 
                                    onnx_model_path: Optional[str] = None, 
                                    output_dir: Optional[str] = None,
                                    model_name: Optional[str] = None,
                                    data_type: str = "FP32") -> Optional[str]:
        actual_onnx_path = onnx_model_path if onnx_model_path else self.onnx_model_path
        if not actual_onnx_path or not os.path.exists(actual_onnx_path):
            self.logger.error(f"ONNX model path '{actual_onnx_path}' not found or not provided. Cannot convert to OpenVINO IR.")
            return None

        if not self.ml_vectorizer:
            self.logger.error("Vectorizer not available. Cannot determine input shape for MO.")
            return None

        actual_output_dir = output_dir if output_dir else os.path.dirname(actual_onnx_path)
        if not actual_output_dir: 
            actual_output_dir = "." 
        os.makedirs(actual_output_dir, exist_ok=True)

        actual_model_name = model_name
        if not actual_model_name:
            base_onnx_name = os.path.splitext(os.path.basename(actual_onnx_path))[0]
            actual_model_name = f"{base_onnx_name}_ir" 
        
        self.ir_model_xml_path = os.path.join(actual_output_dir, actual_model_name + ".xml")
        self.ir_model_bin_path = os.path.join(actual_output_dir, actual_model_name + ".bin")

        try:
            num_features = len(self.ml_vectorizer.vocabulary_)
            if num_features == 0: 
                dummy_transformed = self.ml_vectorizer.transform(["dummy test string"])
                num_features = dummy_transformed.shape[1]
            if num_features == 0:
                self.logger.error("Could not determine number of features from vectorizer for input_shape.")
                return None
            input_shape = f"[1,{num_features}]" 
        except Exception as e:
            self.logger.error(f"Error determining input shape from vectorizer: {e}")
            return None

        mo_command_executable = "mo" 
        cmd = [
            mo_command_executable,
            "--input_model", actual_onnx_path,
            "--output_dir", actual_output_dir,
            "--model_name", actual_model_name,
            "--input_shape", input_shape,
            "--data_type", data_type
        ]
        
        cmd_str = ' '.join([f'"{c}"' if ' ' in c else c for c in cmd])
        self.logger.info(f"Constructed OpenVINO Model Optimizer command: {cmd_str}")
        self.logger.info(f"To convert the ONNX model to OpenVINO IR, please run the command in an OpenVINO-initialized environment.")
        self.logger.info(f"CMD: {cmd_str}")
        
        self.logger.info("Execution of MO command is simulated. IR model paths are set to expected values.")
        return self.ir_model_xml_path 

    def load_openvino_ir_model(self, ir_xml_path: str) -> bool:
        self.logger.info(f"Attempting to load OpenVINO IR model from: {ir_xml_path}")
        bin_path = ir_xml_path.replace(".xml", ".bin") # Standard convention

        if not os.path.exists(ir_xml_path):
            self.logger.error(f"OpenVINO IR model .xml file not found: {ir_xml_path}")
            return False
        if not os.path.exists(bin_path):
            self.logger.error(f"OpenVINO IR model .bin file not found: {bin_path}")
            return False
        
        try:
            core = Core()
            model_ir = core.read_model(model=ir_xml_path) # Removed bin_path, read_model finds it
            self.compiled_model_ir = core.compile_model(model=model_ir, device_name="CPU")
            self.ir_model_xml_path = ir_xml_path 
            self.ir_model_bin_path = bin_path # Store for reference
            self.logger.info(f"OpenVINO IR model loaded and compiled successfully from {ir_xml_path}.")
            return True
        except Exception as e:
            self.logger.error(f"Error loading or compiling OpenVINO IR model from {ir_xml_path}: {e}")
            self.logger.debug(traceback.format_exc())
            self.compiled_model_ir = None
            self.ir_model_xml_path = None 
            self.ir_model_bin_path = None
            return False

    def predict_vulnerabilities_openvino(self, code_content: str, file_path: Optional[str] = None) -> Dict[str, Any]:
        file_scanned_name = os.path.basename(file_path) if file_path else "direct_content_scan"
        if not self.compiled_model_ir:
            self.logger.error("OpenVINO IR model not compiled/loaded. Cannot classify.")
            return {"file_scanned": file_scanned_name, "ml_findings": [], "status": "error_ir_model_not_loaded", "engine_type": "openvino_ir", "error": "OpenVINO IR model not ready."}
        if not self.ml_vectorizer:
            self.logger.error("Vectorizer not loaded. Cannot preprocess for OpenVINO IR model.")
            return {"file_scanned": file_scanned_name, "ml_findings": [], "status": "error_no_vectorizer", "engine_type": "openvino_ir", "error": "Vectorizer not loaded."}
        if not self.ml_model or not hasattr(self.ml_model, 'classes_'): 
            self.logger.error("Original scikit-learn model (for class labels) not loaded.")
            return {"file_scanned": file_scanned_name, "ml_findings": [], "status": "error_no_class_labels", "engine_type": "openvino_ir", "error": "Class labels unavailable."}

        ml_findings = []
        try:
            tokens = self._c_code_tokenizer(code_content)
            processed_code_for_tfidf = " ".join(tokens)
            vectorized_snippet_sparse = self.ml_vectorizer.transform([processed_code_for_tfidf])
            if vectorized_snippet_sparse is None:
                 return {"file_scanned": file_scanned_name, "ml_findings": [], "status": "error_preprocess_failed", "engine_type": "openvino_ir", "error": "Preprocessing failed for OpenVINO."}

            numpy_input_array = vectorized_snippet_sparse.toarray().astype(numpy.float32)
            
            input_layer = self.compiled_model_ir.input(0)
            output_layer = self.compiled_model_ir.output(0)
            
            results = self.compiled_model_ir({input_layer.any_name: numpy_input_array}) # Using dict input
            output_data = results[output_layer]

            probabilities = output_data[0] 
            predicted_idx = int(numpy.argmax(probabilities))
            predicted_label = str(self.ml_model.classes_[predicted_idx])
            confidence = float(probabilities[predicted_idx])
            
            vulnerable_class_label = "vulnerable" # As defined in training
            if predicted_label == vulnerable_class_label:
                ml_findings.append({
                    "vulnerability_type": predicted_label, "confidence": confidence,
                    "details": "ML model (OpenVINO IR) predicted a potential vulnerability.",
                    "line_number_start": -1, "line_number_end": -1,
                    "snippet_if_applicable": code_content[:200] + "..." if len(code_content) > 200 else code_content
                })
            self.logger.info(f"  ML prediction (OpenVINO IR): '{predicted_label}', Confidence (for '{vulnerable_class_label}' class): {confidence:.4f}")

        except Exception as e:
            self.logger.error(f"Error during OpenVINO IR ML prediction: {e}")
            self.logger.debug(traceback.format_exc())
            return {
                "file_scanned": file_scanned_name, "ml_findings": [], "status": "error_openvino_prediction",
                "engine_type": "openvino_ir", "error_message": str(e),
                "model_path_used": self.ir_model_xml_path, "vectorizer_path_used": self.ml_vectorizer_path
            }

        return {
            "file_scanned": file_scanned_name,
            "ml_findings": ml_findings,
            "status": "ml_prediction_complete",
            "engine_type": "openvino_ir", 
            "model_path_used": self.ir_model_xml_path,
            "vectorizer_path_used": self.ml_vectorizer_path
        }


if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    main_logger = logging.getLogger("VulnerabilityDetectorExample") 

    dummy_corpus_train = [
        "strcpy(dst, src); // vulnerable", "memcpy(dst, src, size); // vulnerable",
        "char safe_array[100]; // non-vulnerable", "gets(buffer); // vulnerable",
        "snprintf(buf, size, \"hello\"); // non-vulnerable", "sprintf(buf, format_str, val); // vulnerable",
        "char *user_input = get_user_input(); system(user_input); // vulnerable",
        "const char *cmd = \"ls\"; system(cmd); // non-vulnerable (if cmd is truly const)" 
    ]
    dummy_labels_train = [
        "vulnerable", "vulnerable", "non-vulnerable", "vulnerable", 
        "non-vulnerable", "vulnerable", "vulnerable", "non-vulnerable"
    ]

    test_model_dir = "test_vuln_detector_models"
    os.makedirs(test_model_dir, exist_ok=True)
    test_model_path = os.path.join(test_model_dir, "test_vuln_model.joblib")
    test_vectorizer_path = os.path.join(test_model_dir, "test_vuln_vectorizer.pkl")
    expected_onnx_path = test_model_path.replace(".joblib", ".onnx")
    expected_ir_model_name = os.path.splitext(os.path.basename(expected_onnx_path))[0] + "_ir"
    expected_ir_xml_path = os.path.join(test_model_dir, expected_ir_model_name + ".xml") # Path for IR model

    main_logger.info("--- Testing ML Model Training, ONNX Export, and MO Command Generation ---")
    detector_train = VulnerabilityDetector(logger=main_logger, ml_model_path=test_model_path, ml_vectorizer_path=test_vectorizer_path)
    train_results = detector_train.train_vulnerability_model(dummy_corpus_train, dummy_labels_train)
    main_logger.info(f"Training results: {train_results}")
    
    assert train_results["status"] == "training_complete"
    assert os.path.exists(test_model_path)
    assert os.path.exists(test_vectorizer_path)
    assert train_results.get("onnx_model_path") == expected_onnx_path
    assert os.path.exists(expected_onnx_path)
    assert train_results.get("ir_model_xml_path") == expected_ir_xml_path # MO command was generated
    main_logger.info(f"Model artifacts created in {test_model_dir}")

    main_logger.info("\n--- Testing Inference (OpenVINO Preferred) ---")
    # For this test to use OpenVINO, the user must manually run the MO command logged during training.
    # Otherwise, it will fall back to scikit-learn.
    detector_infer = VulnerabilityDetector(
        logger=main_logger, 
        ml_model_path=test_model_path, 
        ml_vectorizer_path=test_vectorizer_path,
        ir_model_xml_path=expected_ir_xml_path # Pass the expected IR path
    )
    
    # Check which model loaded
    if detector_infer.compiled_model_ir:
        main_logger.info("OpenVINO IR model was successfully loaded. Inference will use OpenVINO.")
    elif detector_infer.ml_model:
        main_logger.info("OpenVINO IR model NOT loaded (or files not found). Inference will use scikit-learn.")
    else:
        main_logger.error("Neither OpenVINO nor scikit-learn model could be loaded for inference test.")


    test_vuln_code = "char input[10]; gets(input);"
    prediction_results = detector_infer.predict_vulnerabilities_ml(test_vuln_code, "test_vuln_sample.c") # Unified call
    main_logger.info(f"Prediction for '{test_vuln_code}': {json.dumps(prediction_results, indent=2)}")
    assert prediction_results["status"] == "ml_prediction_complete"
    
    if detector_infer.compiled_model_ir: # If OpenVINO model was loaded and used
        assert prediction_results["engine_type"] == "openvino_ir"
        main_logger.info("Verified OpenVINO engine was used.")
    else: # Fallback to scikit-learn
        assert prediction_results["engine_type"] == "sklearn_logistic_regression"
        main_logger.info("Verified scikit-learn engine was used (OpenVINO IR model likely not found).")

    if prediction_results["ml_findings"]:
        assert prediction_results["ml_findings"][0]["vulnerability_type"] == "vulnerable" 
        main_logger.info("Correctly predicted as vulnerable.")
    else:
        main_logger.warning("ML model did not predict the test snippet as vulnerable (this might be due to tiny dataset or engine used).")


    main_logger.info("\n--- Cleaning up test files ---")
    paths_to_clean = [test_model_path, test_vectorizer_path, expected_onnx_path]
    if detector_train.ir_model_xml_path: 
        paths_to_clean.append(detector_train.ir_model_xml_path)
    if detector_train.ir_model_bin_path:
        paths_to_clean.append(detector_train.ir_model_bin_path)
        
    for f_path in paths_to_clean:
        if f_path and os.path.exists(f_path): # Check f_path is not None
            os.remove(f_path)
            main_logger.info(f"Removed {f_path}")
            
    if os.path.exists(test_model_dir) and not os.listdir(test_model_dir): 
        os.rmdir(test_model_dir)
        main_logger.info(f"Cleaned up test model directory: {test_model_dir}")
    elif os.path.exists(test_model_dir):
         main_logger.warning(f"Test model directory {test_model_dir} not empty after cleanup, not removing.")

    main_logger.info("--- All VulnerabilityDetector tests completed ---")
```
